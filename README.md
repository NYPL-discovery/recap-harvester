# recap-harvester

This application keeps our databases & search index informed about additions &
updates to, and deletions of, partner bibs and items. It does that by parsing
files that are generated by HTC and posting them to the `BibPostRequest-env` &
`ItemPostRequest-env` streams.

## When does this app run?

This app can be run in 2 different scenarios.

1. The [initial seeding of our databases & index](#initial). (HTC generates a massive zip of our partners' items)
2. On a [nightly basis](#nightly), it downloads HTC-generated files that represent bibliographic additions, updates,
and deletions.

## <a name="nightly"></a> Development & Deployment Instructions for Nightly Updates

TODO: An explanation of the order of operations and an overview
of what this app does on the SFTP server and locally.

### Installing / Building Locally

The following environment variables need to be set.
Locally, this can be done in [an STS run configuration](https://stackoverflow.com/a/40482553).

```
AWS_ACCESS_KEY_ID="USED-TO-POST-TO-KINESIS"
AWS_SECRET_ACCESS_KEY="USED-TO-POST-TO-KINESIS"
accessionDirectory=[remote-accession-directory-name]
bibSchemaPath=[/current-schemas/BibPostRequest]
deaccessionDirectory=[remote-deaccession-directory-name]
ftpBaseLocation=[remote/path/to/parent/of/accession/and/deaccession/dirs]
ftpCompressedFilesFailedDirectory=[remote-directory-name-for-error-files-to-go]
ftpCompressedFilesProcessedDirectory=[remote-directory-name-for-processed-files-to-go]
ftpHostName="username@fqdn.com"
ftpPort="2222"
ftpPrivateKeyFileLocation="/full/path-to/sftp-servers/private-key"
itemSchemaPath="/current-schemas/ItemPostRequest"
kinesisBibStream="BibPostRequest"
kinesisItemStream="ItemPostRequest"
onlyDoUpdates="true"
platformAPIBasePath="https://API-DOMAIN.com/api/v0.1"
scsbexportstagingLocation="/local/full/path/to/where/files/get/downloaded"
uncompressedFilesDirectoryForUpdates="/local/full/path/to/where/files/get/downloaded"
```

### Deploying to Elastic Beanstalk

TODO: fill this out as we figure it out.

## <a name="initial"></a> Development & Deployment Instructions for Initial Load

This is for the initial load of data.
TODO: note saying that this requires manual downloading & unzipping from SFTP.

### Installing / Building Locally

#### Environment Variables

The following environment variables need to be set. For different options to set AWS credentials, please refer to http://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html.

```
AWS_ACCESS_KEY_ID=[used-to-publish-to-kinesis]
AWS_SECRET_ACCESS_KEY=[used-to-publish-to-kinesis]
bibSchemaAPI=https://[domain.example.com]/api/v0.1/current-schemas/BibPostRequest
itemSchemaAPI=https://[domain.example.com]/api/v0.1/current-schemas/ItemPostRequest
kinesisBibStream=[snip]
kinesisItemStream=[snip]
scsbexportstagingLocation=/var/app/current/scsbxml
```

...can we add specific IDE instructions...(or things useful to future maintainers)

### Deploying to Elastic Beanstalk

#### Initial Deploy

1.  `mvn clean package`
1.  `eb init Recap-Harvester --profile [profile name]`
1.  Create application

  ```bash
  eb create recap-harvester-[environment] \
      --instance_type m4.large \
      --instance_profile cloudwatchable-beanstalk \
      --cname recap-harvester-[environment] \
      --vpc.id public-vpc \
      --vpc.elbsubnets public-subnet-id-1 \
      --vpc.ec2subnets private-subnet-id-1 \
      --tags Project=Discovery,harvester=recap_harvester \
      --keyname dgdvteam \
      --scale 1 \
      --envvars KEYFROMABOVE="value",KEYFROMABOVE2="value" \
      --profile your-aws-profile-name
  ```
